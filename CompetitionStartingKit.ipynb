{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqpo-u3SJ6BL"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t8eHlqdVJ0oP"
   },
   "source": [
    "Let's have a look at the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "input_data_path = Path(os.environ.get('INPUT_DATA_PATH', '.'))\n",
    "output_data_path = Path(os.environ.get('OUTPUT_DATA_PATH', '.'))\n",
    "\n",
    "train_file = str(input_data_path / \"data_train.npz\")\n",
    "test_file = str(input_data_path / \"data_test.npz\")\n",
    "prediction_file = str(output_data_path / \"data_test_prediction.npz\")\n",
    "\n",
    "\n",
    "if not (os.path.isfile(train_file) and\n",
    "        os.path.isfile(test_file)):\n",
    "    if not os.path.isfile(\"input_public_data.zip\"):\n",
    "        !wget https://codalab.coresearch.club/my/datasets/download/37304c34-1d4a-4f43-bcb2-1fdeb37c5cba -O input_public_data.zip\n",
    "    !unzip -n input_public_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "PnwQTWoUuV1B",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "KVTLnfHsvH29",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_real = np.load(train_file, allow_pickle=True)\n",
    "\n",
    "# This is the calorimeter response:\n",
    "energy = data_real['EnergyDeposit']\n",
    "\n",
    "# These are the quantities we want to predict\n",
    "momentum = data_real['ParticleMomentum'][:,:2]\n",
    "coordinate = data_real['ParticlePoint'][:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "LxBkEZ-HGGkY",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "d8886772-a886-4934-e04a-05d9b96ef04e"
   },
   "outputs": [],
   "source": [
    "print('energy.shape:', energy.shape)\n",
    "print('momentum.shape:', momentum.shape)\n",
    "print('coordinate.shape:', coordinate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KtNiLcfTKZAT"
   },
   "source": [
    "So, we have images of 30x30 pixels and we want to predict 4 numbers for each of them: x, y, px and py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Z9d8ZfTKmkS"
   },
   "source": [
    "Let's have a look at some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "qo0cQCrBFkhs",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "adq1QO8LFqYN",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "feb34f3e-3fcd-445c-86bc-171d87e438d8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.subplot(221)\n",
    "plt.imshow(energy[5])\n",
    "plt.subplot(222)\n",
    "plt.imshow(energy[50])\n",
    "plt.subplot(223)\n",
    "plt.imshow(energy[500])\n",
    "plt.subplot(224)\n",
    "plt.imshow(energy[5000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IXXwCOt1KvKN"
   },
   "source": [
    "It's also worth knowing how the targets are distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "scFXIWjZwAFq",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "3ddc84f3-9764-4c35-bfdc-fb7dd4f05954"
   },
   "outputs": [],
   "source": [
    "plt.scatter(*momentum.T, s=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "nIYBOK8HGAbW",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "5a5e05cd-4c84-4442-cfea-4d7835de08e1"
   },
   "outputs": [],
   "source": [
    "plt.scatter(*coordinate.T, s=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uAeQH_sQK8IQ"
   },
   "source": [
    "Naive approach: can we predict the coordinates from the center of mass position of the calorimeter response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "3mt3FiINGqXz",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "b5104903-df1c-42d7-d5dd-2774bd9658bb"
   },
   "outputs": [],
   "source": [
    "energy_density = energy / energy.sum(axis=(1, 2), keepdims=True)\n",
    "\n",
    "cell_coords = np.stack([*np.meshgrid(\n",
    "    np.arange(energy.shape[1]),\n",
    "    np.arange(energy.shape[2])\n",
    ")], axis=-1)[None,...]\n",
    "\n",
    "center_of_mass = (energy_density[...,None] * cell_coords).sum(axis=(1, 2))\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.subplot(121)\n",
    "plt.scatter(coordinate[:,0], center_of_mass[:,0], s=5)\n",
    "plt.subplot(122)\n",
    "plt.scatter(coordinate[:,1], center_of_mass[:,1], s=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YUoqUZHCLf3i"
   },
   "source": [
    "Looks like the correlation isn't too strong. Maybe higher moments would give us a better picture, but we'll leave such experiments to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTLaOd8rNULd"
   },
   "source": [
    "# Example solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "c7jiMXIHynma",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "import torch.optim as optim\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "ZBuDIFV-N-Vp",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "ac3e10a1-1a8a-4f1b-919c-08804970bbaf"
   },
   "outputs": [],
   "source": [
    "X = energy[:,None,...] # adding Channels dimension\n",
    "Y = np.concatenate([coordinate, momentum], axis=1)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "E4fWo7mawEs5",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def make_torch_dataset(X, Y, batch_size, shuffle=True):\n",
    "    X = torch.tensor(X).float()\n",
    "    Y = torch.tensor(Y).float()\n",
    "    ds = utils.TensorDataset(X, Y)\n",
    "    return torch.utils.data.DataLoader(\n",
    "        ds, batch_size=batch_size,\n",
    "        pin_memory=True, shuffle=shuffle\n",
    "    )\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "ds_train = make_torch_dataset(X_train, Y_train, BATCH_SIZE)\n",
    "ds_val = make_torch_dataset(X_val, Y_val, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### do we need this Conv block?\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# We are going to build a model from several convolutional blocks.\n",
    "# I.e. it's going to be:\n",
    "#\n",
    "#       [Conv2d -> Conv2d -> MaxPool2d] x 4\n",
    "#     \n",
    "# So why don't we define such a block as a separate Module?\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,     # <== number of input channels to the 1st convolution\n",
    "                 interm_channels, # <== outputs of the 1st / inputs of the 2nd convolution\n",
    "                 out_channels,    # <== outputs of the 2nd convolution\n",
    "                 use_batchnorm,   # <== whether we'll use batchnorm\n",
    "                 initialization,  # <== function that'll initialize the weights\n",
    "                 pad_1 = 1, pad_2 = 1):    # <== padd at 1st and 2nd conv \n",
    "        # First we run the base class constructor\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        # And then define all the layers used within a block\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
    "                               out_channels=interm_channels,\n",
    "                               kernel_size=3, padding=pad_1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=interm_channels,\n",
    "                               out_channels=out_channels,\n",
    "                               kernel_size=3, padding=pad_2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        if use_batchnorm:\n",
    "            self.bn1 = nn.BatchNorm2d(interm_channels)\n",
    "            self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # If initialization function provided, call it on the weights of the model\n",
    "        if initialization is not None:\n",
    "            initialization(self.conv1.weight)\n",
    "            initialization(self.conv2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        if self.use_batchnorm:\n",
    "            x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        if self.use_batchnorm:\n",
    "            x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "tdlmdZrMywul",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Disclaimer: this might not be the best architecture for the task\n",
    "\n",
    "# class Regressor(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Regressor, self).__init__()\n",
    "#         self.conv1 = Conv2d(in_channels=1,\n",
    "#                                out_channels=3,\n",
    "#                                kernel_size=7)\n",
    "#         self.pool = nn.MaxPool2d((4, 4))\n",
    "#         self.conv2 = nn.Conv2d(in_channels=3,\n",
    "#                                out_channels=8,\n",
    "#                                kernel_size=4)\n",
    "\n",
    "#         self.fc1 = nn.Linear(3 * 3 * 8, 32)\n",
    "#         self.fc2 = nn.Linear(32, 2 + 2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = self.pool(x)\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = x.view(len(x), -1)\n",
    "\n",
    "#         x = F.relu(self.fc1(x))\n",
    "\n",
    "#         return self.fc2(x)\n",
    "\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self, \n",
    "                initialization=(lambda w: torch.nn.init.kaiming_normal_(w, nonlinearity='relu')),\n",
    "                use_batchnorm = True,\n",
    "                drop = 0.04):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.drop = drop\n",
    "        if self.drop is not None:\n",
    "            self.drop_lay = nn.Dropout(p=drop)\n",
    "        \n",
    "        # Convolutional layers:                                         # 1x30x30 (Channels x height x width)\n",
    "        self.conv1 = ConvBlock(1, 4, 8, use_batchnorm, initialization, pad_1 = 2, pad_2 = 1) \n",
    "        self.conv2 = ConvBlock(8, 16, 32, use_batchnorm, initialization, pad_1 = 1, pad_2 = 1)\n",
    "        self.conv3 = ConvBlock(32, 32, 64, use_batchnorm, initialization, pad_1 = 1, pad_2 = 1)\n",
    "        self.conv4 = ConvBlock(64, 64, 64, use_batchnorm, initialization, pad_1 = 1, pad_2 = 1)\n",
    "#         self.conv5 = ConvBlock(64, 64, 64, use_batchnorm, initialization, pad_1 = 1, pad_2 = 1) ## extra\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(64*2*2, 64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.fc3 = nn.Linear(16, 4)\n",
    "   \n",
    "    \n",
    "#         self.fc1 = nn.Linear(64*2*2, 128)\n",
    "#         self.fc2 = nn.Linear(128, 64)\n",
    "#         self.fc3 = nn.Linear(64, 16)\n",
    "#         self.fc4 = nn.Linear(16, 4)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # If initialization function provided, call it on the weights of the model\n",
    "        if initialization is not None:\n",
    "            initialization(self.fc1.weight)\n",
    "            initialization(self.fc2.weight)\n",
    "            initialization(self.fc3.weight)\n",
    "#             initialization(self.fc4.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "#         x = self.conv5(x)\n",
    "        \n",
    "\n",
    "        x = x.view(len(x), -1)\n",
    "#         x = x.flatten(1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if self.drop is not None:\n",
    "            x = self.drop_lay(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "#         if self.drop is not None:\n",
    "#             x = self.drop_lay(x)\n",
    "#         x = F.relu(self.fc3(x))\n",
    "#         if self.drop is not None:\n",
    "#             x = self.drop_lay(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "MQbp_fgby8_d",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "30ef6c88-0b98-405a-fc87-dc782b39b767"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') ## change this for submission\n",
    "# device = torch.device('cpu')\n",
    "# device\n",
    "regressor = Regressor(initialization = None, drop =None).to(device)\n",
    "learning_rate = 2.0e-3\n",
    "opt = optim.Adam(regressor.parameters(), lr=learning_rate)\n",
    "# Disclaimer: this might not be the best loss function for this task.\n",
    "# loss_fn = torch.nn.L1Loss().to(device)\n",
    "loss_fn = torch.nn.MSELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "KSBfriTgy6OO",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "PFhD7tURzCQN",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "QYyOjzMizUYf",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def metric_relative_mse(y_true, y_pred):\n",
    "    return (\n",
    "        (y_true - y_pred).pow(2).mean(dim=0) / y_true.pow(2).mean(dim=0)\n",
    "    )\n",
    "\n",
    "def metric_relative_mse_total(y_true, y_pred):\n",
    "    return metric_relative_mse(y_true, y_pred).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "-q8L1r1FzgFh",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "KaDRrfUezvkr",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def run_training(epochs=5):\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "    metrics_train = []\n",
    "    metrics_val = []\n",
    "    per_component_metrics_train = []\n",
    "    per_component_metrics_val = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for batch_X, batch_Y in ds_train:\n",
    "            batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "\n",
    "            pred = regressor(batch_X)\n",
    "            loss = loss_fn(pred, batch_Y)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            losses_train.append(loss.item())\n",
    "            metrics_train.append(\n",
    "                metric_relative_mse_total(batch_Y, pred).item()\n",
    "            )\n",
    "\n",
    "            per_component_metrics_train.append(\n",
    "                metric_relative_mse(batch_Y, pred).detach().cpu().numpy()\n",
    "            )\n",
    "\n",
    "        avg_loss, avg_metrics, avg_per_component_metrics = [], [], []\n",
    "        for batch_X, batch_Y in ds_val:\n",
    "            batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "\n",
    "            pred = regressor(batch_X)\n",
    "            loss = loss_fn(pred, batch_Y)\n",
    "\n",
    "            avg_loss.append(loss.item())\n",
    "            avg_metrics.append(\n",
    "                metric_relative_mse_total(batch_Y, pred).item()\n",
    "            )\n",
    "            avg_per_component_metrics.append(\n",
    "                metric_relative_mse(batch_Y, pred).detach().cpu().numpy()\n",
    "            )\n",
    "        losses_val.append(np.mean(avg_loss))\n",
    "        metrics_val.append(np.mean(avg_metrics))\n",
    "        per_component_metrics_val.append(\n",
    "            np.mean(avg_per_component_metrics, axis=0)\n",
    "        )\n",
    "\n",
    "\n",
    "        clear_output()\n",
    "        plt.figure(figsize=(18, 4.5))\n",
    "\n",
    "        plt.subplot(131)\n",
    "\n",
    "        plt.title(\"Loss\")\n",
    "        plt.plot(losses_train, label='train')\n",
    "        plt.plot(\n",
    "            np.linspace(0, len(losses_train), len(losses_val), endpoint=False),\n",
    "            losses_val, label='val'\n",
    "        )\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(132)\n",
    "\n",
    "        plt.title(\"Metric (per component)\")\n",
    "        ms_train = np.array(per_component_metrics_train).T\n",
    "        ms_val = np.array(per_component_metrics_val).T\n",
    "        for i, (m_train, m_val, color) in enumerate(zip(ms_train,\n",
    "                                                        ms_val,\n",
    "                                                        plt.rcParams['axes.prop_cycle'])):\n",
    "            plt.plot(m_train, label=f'train (component {i})', c=color['color'])\n",
    "            plt.plot(\n",
    "                np.linspace(0, len(m_train), len(m_val), endpoint=False),\n",
    "                m_val, '--', label=f'val (component {i})', c=color['color']\n",
    "            )\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(133)\n",
    "\n",
    "        plt.title(\"Metric (total)\")\n",
    "        plt.plot(metrics_train, label='train')\n",
    "        plt.plot(\n",
    "            np.linspace(0, len(metrics_train), len(metrics_val), endpoint=False),\n",
    "            metrics_val, label='val'\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    print(f\"Minimum val. metrics = {np.min(metrics_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.3968\n",
    "#0.3843\n",
    "#0.4461\n",
    "#0.43\n",
    "#0.4487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "K7WO5pPCzzdk",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "953da882-8ce2-480e-b527-e179705f2abe"
   },
   "outputs": [],
   "source": [
    "run_training(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "5bN3HPY10DAV",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_test = np.load(test_file, allow_pickle=True)\n",
    "X_test = data_test['EnergyDeposit'][:,None,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "uEUeTOuI120h",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "prediction_test = regressor(torch.tensor(X_test, device=device).float()).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "jKDDvcBr1-Sa",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "coordinate_test, momentum_test = (\n",
    "    prediction_test.detach().numpy()[:, :2],\n",
    "    prediction_test.detach().numpy()[:, 2:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "QUGKOcHl2HMj",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.savez_compressed(prediction_file,\n",
    "                    ParticlePoint=coordinate_test,\n",
    "                    ParticleMomentum=momentum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "JNs5peky2MRc",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CompetitionStartingKit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
